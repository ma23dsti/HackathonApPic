{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sGHf21U0LyAV"
   },
   "source": [
    "# PREPARATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FYhwIiqfLZgw"
   },
   "source": [
    "## Driving variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:38:04.836176Z",
     "iopub.status.busy": "2025-04-05T09:38:04.835838Z",
     "iopub.status.idle": "2025-04-05T09:38:04.840086Z",
     "shell.execute_reply": "2025-04-05T09:38:04.839155Z",
     "shell.execute_reply.started": "2025-04-05T09:38:04.836155Z"
    },
    "id": "nDUo_WvAxb-e",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SKIP_SECTION_COLAB = True\n",
    "SKIP_SECTION_KAGGLE = not SKIP_SECTION_COLAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoBhv_4Q0F1c"
   },
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:38:04.848713Z",
     "iopub.status.busy": "2025-04-05T09:38:04.848466Z",
     "iopub.status.idle": "2025-04-05T09:38:08.089549Z",
     "shell.execute_reply": "2025-04-05T09:38:08.088361Z",
     "shell.execute_reply.started": "2025-04-05T09:38:04.848693Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mplcursors in /usr/local/lib/python3.10/dist-packages (0.6)\n",
      "Requirement already satisfied: matplotlib!=3.7.1,>=3.1 in /usr/local/lib/python3.10/dist-packages (from mplcursors) (3.7.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.7.1,>=3.1->mplcursors) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.7.1,>=3.1->mplcursors) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.7.1,>=3.1->mplcursors) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.7.1,>=3.1->mplcursors) (1.4.7)\n",
      "Requirement already satisfied: numpy<2,>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.7.1,>=3.1->mplcursors) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.7.1,>=3.1->mplcursors) (24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.7.1,>=3.1->mplcursors) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.7.1,>=3.1->mplcursors) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.7.1,>=3.1->mplcursors) (2.9.0.post0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib!=3.7.1,>=3.1->mplcursors) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib!=3.7.1,>=3.1->mplcursors) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib!=3.7.1,>=3.1->mplcursors) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib!=3.7.1,>=3.1->mplcursors) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib!=3.7.1,>=3.1->mplcursors) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib!=3.7.1,>=3.1->mplcursors) (2.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.7.1,>=3.1->mplcursors) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.20->matplotlib!=3.7.1,>=3.1->mplcursors) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.20->matplotlib!=3.7.1,>=3.1->mplcursors) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2,>=1.20->matplotlib!=3.7.1,>=3.1->mplcursors) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2,>=1.20->matplotlib!=3.7.1,>=3.1->mplcursors) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2,>=1.20->matplotlib!=3.7.1,>=3.1->mplcursors) (2024.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install mplcursors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:38:08.091156Z",
     "iopub.status.busy": "2025-04-05T09:38:08.090901Z",
     "iopub.status.idle": "2025-04-05T09:38:08.097542Z",
     "shell.execute_reply": "2025-04-05T09:38:08.096753Z",
     "shell.execute_reply.started": "2025-04-05T09:38:08.091135Z"
    },
    "id": "n2zlTYh3tgsa",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from keras.callbacks import Callback\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import datetime\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import gc\n",
    "import json\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Reshape\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from keras.models import Model\n",
    "import mplcursors\n",
    "from keras.layers import Input\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorflow.keras.saving import register_keras_serializable\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "import sys\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VufpveDpJJnM"
   },
   "source": [
    "## Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:38:08.099249Z",
     "iopub.status.busy": "2025-04-05T09:38:08.099001Z",
     "iopub.status.idle": "2025-04-05T09:38:08.126604Z",
     "shell.execute_reply": "2025-04-05T09:38:08.125940Z",
     "shell.execute_reply.started": "2025-04-05T09:38:08.099224Z"
    },
    "id": "mrKbxiFMtgsd",
    "outputId": "c4ba71bd-a536-4130-b823-4035275d4e96",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:38:08.128068Z",
     "iopub.status.busy": "2025-04-05T09:38:08.127792Z",
     "iopub.status.idle": "2025-04-05T09:38:08.140942Z",
     "shell.execute_reply": "2025-04-05T09:38:08.140059Z",
     "shell.execute_reply.started": "2025-04-05T09:38:08.128039Z"
    },
    "id": "vzzvWfUKtgsf",
    "outputId": "6d156c1f-456e-4d4c-c986-1e474820983b",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is set up and ready to use.\n"
     ]
    }
   ],
   "source": [
    "# Limit TensorFlow to only use the first GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Set TensorFlow to only use the GPU and not fall back to CPU\n",
    "        tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        print(\"GPU is set up and ready to use.\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU found, using CPU instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:38:08.142262Z",
     "iopub.status.busy": "2025-04-05T09:38:08.141979Z",
     "iopub.status.idle": "2025-04-05T09:38:08.153866Z",
     "shell.execute_reply": "2025-04-05T09:38:08.153072Z",
     "shell.execute_reply.started": "2025-04-05T09:38:08.142229Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Configure memory growth for GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c6kZ1k7kJcEx"
   },
   "source": [
    "## Mount disk and define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:38:08.155111Z",
     "iopub.status.busy": "2025-04-05T09:38:08.154835Z",
     "iopub.status.idle": "2025-04-05T09:38:08.167287Z",
     "shell.execute_reply": "2025-04-05T09:38:08.166483Z",
     "shell.execute_reply.started": "2025-04-05T09:38:08.155084Z"
    },
    "id": "wbXcfSWetgsj",
    "outputId": "ab3a0940-26df-449c-a6f9-87fcdb424fc9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check disk content (Kaggle) or mount disk (Google Colab)\n",
    "if not SKIP_SECTION_KAGGLE:\n",
    "  os.listdir('/kaggle/input')\n",
    "\n",
    "if not SKIP_SECTION_COLAB:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:38:08.168473Z",
     "iopub.status.busy": "2025-04-05T09:38:08.168205Z",
     "iopub.status.idle": "2025-04-05T09:38:08.183984Z",
     "shell.execute_reply": "2025-04-05T09:38:08.183363Z",
     "shell.execute_reply.started": "2025-04-05T09:38:08.168454Z"
    },
    "id": "8yLEq1I_tgsm",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Data paths\n",
    "if not SKIP_SECTION_KAGGLE:\n",
    "  path_data = \"/kaggle/input/dossier-donnees/dossier_donnees/jour2/data/\"\n",
    "  path_preprocessed_data = \"/kaggle/input/dossier-donnees/dossier_donnees/jour2/data/preprocessed_data/\"\n",
    "  path_raw_data = \"/kaggle/input/dossier-donnees/dossier_donnees/jour2/data/raw_data/\"    \n",
    "  path_preprocessed_data_window_7 = \"/kaggle/input/preprocessed-data-7/\"\n",
    "\n",
    "if not SKIP_SECTION_COLAB:\n",
    "  path_data = \"/content/drive/MyDrive/DSTI/Hackathon/Time Series/Material_Preparation/Phase_2/dossier_donnees/jour2/data/\"\n",
    "  path_preprocessed_data = \"/content/drive/MyDrive/DSTI/Hackathon/Time Series/Material_Preparation/Phase_2/dossier_donnees/jour2/data/preprocessed_data/\"\n",
    "  path_raw_data = \"/content/drive/MyDrive/DSTI/Hackathon/Time Series/Material_Preparation/Phase_2/dossier_donnees/jour2/data/raw_data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:38:08.186667Z",
     "iopub.status.busy": "2025-04-05T09:38:08.186469Z",
     "iopub.status.idle": "2025-04-05T09:38:08.197643Z",
     "shell.execute_reply": "2025-04-05T09:38:08.196790Z",
     "shell.execute_reply.started": "2025-04-05T09:38:08.186651Z"
    },
    "id": "SQRiZtIYKk0E",
    "outputId": "de881c50-bd07-480f-c7a2-90828c6fb0fe",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the log directory path\n",
    "###log_dir = \"kaggle/input/logs/fit/\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "###os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Print confirmation\n",
    "###print(f\"Directory {log_dir} created for TensorBoard logs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYAGYZ_iL6Vi"
   },
   "source": [
    "# DONNEES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I81b52W3NMf5"
   },
   "source": [
    "## Configurer les générateurs de nombres aléatoires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:38:08.199299Z",
     "iopub.status.busy": "2025-04-05T09:38:08.199066Z",
     "iopub.status.idle": "2025-04-05T09:38:08.213373Z",
     "shell.execute_reply": "2025-04-05T09:38:08.212557Z",
     "shell.execute_reply.started": "2025-04-05T09:38:08.199282Z"
    },
    "id": "E-0qGVSatgso",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if using multi-GPU\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREMIER PREPROCESSING - Raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECOND PREPROCESSING - Fenêtres glissantes de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces deux preprocessing sont effectué par le script présent dans l'Application fournie et renvoie en sortie les 4 fichiers csv utilisés ci-dessous après leur enregistrement dans un dossier dédié (path_preprocessed_data) : x_train, x_train, x_valid, y_valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:38:08.214458Z",
     "iopub.status.busy": "2025-04-05T09:38:08.214230Z",
     "iopub.status.idle": "2025-04-05T09:38:08.228030Z",
     "shell.execute_reply": "2025-04-05T09:38:08.227392Z",
     "shell.execute_reply.started": "2025-04-05T09:38:08.214441Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions choisies:\n",
      "taille_fenetre_a_predire: 60\n",
      "taille_fenetre_observee: 400\n",
      "taille_pas_glissant_train: 13\n",
      "taille_pas_glissant_valid: 65\n"
     ]
    }
   ],
   "source": [
    "# Structure des modèles par défaut\n",
    "taille_fenetre_a_predire_mapping = {\n",
    "    \"taille_fenetre_a_predire\": {\n",
    "        1: {\n",
    "            \"taille_fenetre_observee\": 12,\n",
    "            \"taille_pas_glissant_train\": 13,\n",
    "            \"taille_pas_glissant_valid\": 13\n",
    "        },\n",
    "        5: {\n",
    "            \"taille_fenetre_observee\": 60,\n",
    "            \"taille_pas_glissant_train\": 13,\n",
    "            \"taille_pas_glissant_valid\": 65\n",
    "        },\n",
    "        30: {\n",
    "            \"taille_fenetre_observee\": 300,\n",
    "            \"taille_pas_glissant_train\": 13,\n",
    "            \"taille_pas_glissant_valid\": 65\n",
    "        },\n",
    "        60: {\n",
    "            \"taille_fenetre_observee\": 400,\n",
    "            \"taille_pas_glissant_train\": 13,\n",
    "            \"taille_pas_glissant_valid\": 65\n",
    "        },\n",
    "        300: {\n",
    "            \"taille_fenetre_observee\": 500,\n",
    "            \"taille_pas_glissant_train\": 13,\n",
    "            \"taille_pas_glissant_valid\": 65\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "taille_fenetre_a_predire = 60\n",
    "taille_fenetre_observee, taille_pas_glissant_train, taille_pas_glissant_valid = \\\n",
    "taille_fenetre_a_predire_mapping[\"taille_fenetre_a_predire\"][taille_fenetre_a_predire].values()\n",
    "\n",
    "print(\"Dimensions choisies:\")\n",
    "print(\"taille_fenetre_a_predire:\", taille_fenetre_a_predire)\n",
    "print(\"taille_fenetre_observee:\", taille_fenetre_observee)\n",
    "print(\"taille_pas_glissant_train:\", taille_pas_glissant_train)\n",
    "print(\"taille_pas_glissant_valid:\", taille_pas_glissant_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *** Section pour choisir directement des fichiers x_train, y_train, x_valid, y_valid déjà préprocessés\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:38:08.229234Z",
     "iopub.status.busy": "2025-04-05T09:38:08.228942Z",
     "iopub.status.idle": "2025-04-05T09:38:16.601937Z",
     "shell.execute_reply": "2025-04-05T09:38:16.601018Z",
     "shell.execute_reply.started": "2025-04-05T09:38:08.229186Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions choisies:\n",
      "taille_fenetre_a_predire: 60\n",
      "taille_fenetre_observee: 400\n",
      "taille_pas_glissant_train: 13\n",
      "taille_pas_glissant_valid: 65\n"
     ]
    }
   ],
   "source": [
    "# Fichiers x_train, y_train, x_valid, y_valid déjà préprocessés\n",
    "print(\"Dimensions choisies:\")\n",
    "print(\"taille_fenetre_a_predire:\", taille_fenetre_a_predire)\n",
    "print(\"taille_fenetre_observee:\", taille_fenetre_observee)\n",
    "print(\"taille_pas_glissant_train:\", taille_pas_glissant_train)\n",
    "print(\"taille_pas_glissant_valid:\", taille_pas_glissant_valid)\n",
    "\n",
    "# Choix ces CSV déjà préprocessés, correspondant à l'horizon de prédiction choisi ci-dessus\n",
    "# Version du préprocessing : Novembre 2024 (Phase 1)\n",
    "#path_preprocessed_data = \"/kaggle/input/dossier-donnees/dossier_donnees/jour2/data/preprocessed_data/\"\n",
    "#x_train = pd.read_csv(f\"{path_preprocessed_data}x_train.csv\", header=None)\n",
    "#y_train = pd.read_csv(f\"{path_preprocessed_data}y_train.csv\", header=None)\n",
    "#x_valid = pd.read_csv(f\"{path_preprocessed_data}x_valid.csv\", header=None)\n",
    "#y_valid = pd.read_csv(f\"{path_preprocessed_data}y_valid.csv\", header=None)\n",
    "\n",
    "# Version du préprocessing : Janvier 2025\n",
    "# Exécuter le code de la section juste avant, qui est en dehors de cette section raccourci (## Préprocessing - Générer les données préprocessées)\n",
    "# Données dupliquées regroupées et périodicités non constantes lissées linéairement\n",
    "\n",
    "# Version du préprocessing : Mars 2025\n",
    "path_preprocessed_data = \"/kaggle/input/new-preprocessing/\"\n",
    "x_train = pd.read_csv(f\"{path_preprocessed_data}x_train_s{taille_pas_glissant_train}_o{taille_fenetre_observee}_p{taille_fenetre_a_predire}.csv\", header=None)\n",
    "y_train = pd.read_csv(f\"{path_preprocessed_data}y_train_s{taille_pas_glissant_train}_o{taille_fenetre_observee}_p{taille_fenetre_a_predire}.csv\", header=None)\n",
    "x_valid = pd.read_csv(f\"{path_preprocessed_data}x_valid_s{taille_pas_glissant_valid}_o{taille_fenetre_observee}_p{taille_fenetre_a_predire}.csv\", header=None)\n",
    "y_valid = pd.read_csv(f\"{path_preprocessed_data}y_valid_s{taille_pas_glissant_valid}_o{taille_fenetre_observee}_p{taille_fenetre_a_predire}.csv\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwR5PIDAKAV7"
   },
   "source": [
    "## EDA - EXPLORATION ET ANALYSE DES DONNEES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:38:16.603386Z",
     "iopub.status.busy": "2025-04-05T09:38:16.603045Z",
     "iopub.status.idle": "2025-04-05T09:38:16.607400Z",
     "shell.execute_reply": "2025-04-05T09:38:16.606515Z",
     "shell.execute_reply.started": "2025-04-05T09:38:16.603358Z"
    },
    "id": "MGBBSuXotgst",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get the number of rows and columns for each dataframe\n",
    "x_train_shape = x_train.shape\n",
    "x_valid_shape = x_valid.shape\n",
    "#x_test_shape = x_test.shape\n",
    "y_train_shape = y_train.shape\n",
    "y_valid_shape = y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:38:16.608538Z",
     "iopub.status.busy": "2025-04-05T09:38:16.608308Z",
     "iopub.status.idle": "2025-04-05T09:38:16.630349Z",
     "shell.execute_reply": "2025-04-05T09:38:16.629653Z",
     "shell.execute_reply.started": "2025-04-05T09:38:16.608510Z"
    },
    "id": "Yet8LuTgtgsv",
    "outputId": "273d7b9b-c875-4da8-84b4-7c1e55d436ab",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train - Number of rows: 132019, Number of columns: 400\n",
      "x_valid - Number of rows: 4240, Number of columns: 400\n"
     ]
    }
   ],
   "source": [
    "print(f\"x_train - Number of rows: {x_train_shape[0]}, Number of columns: {x_train_shape[1]}\")\n",
    "print(f\"x_valid - Number of rows: {x_valid_shape[0]}, Number of columns: {x_valid_shape[1]}\")\n",
    "#print(f\"x_test - Number of rows: {x_test_shape[0]}, Number of columns: {x_test_shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:38:16.631278Z",
     "iopub.status.busy": "2025-04-05T09:38:16.631039Z",
     "iopub.status.idle": "2025-04-05T09:38:17.534611Z",
     "shell.execute_reply": "2025-04-05T09:38:17.533727Z",
     "shell.execute_reply.started": "2025-04-05T09:38:16.631258Z"
    },
    "id": "41uBjJ6stgsx",
    "outputId": "91e9c969-3d3d-4c8f-854a-2b236d68d9fb",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******x_train\n",
      "Minimum values:\n",
      " 176.0\n",
      "\n",
      "Maximum values:\n",
      " 762170.0\n",
      "\n",
      "Mean (Average) values:\n",
      " 77548.39447941205\n",
      "\n",
      "Standard Deviation values:\n",
      " 77134.6381501306\n",
      "*******y_val\n",
      "Minimum values:\n",
      " 176.0\n",
      "\n",
      "Maximum values:\n",
      " 381085.0\n",
      "\n",
      "Mean (Average) values:\n",
      " 52548.51355738994\n",
      "\n",
      "Standard Deviation values:\n",
      " 54288.12722779933\n"
     ]
    }
   ],
   "source": [
    "# Calculate min, max, mean, and std\n",
    "min_x_train = x_train.values.min()\n",
    "max_x_train = x_train.values.max()\n",
    "mean_x_train = x_train.values.mean()\n",
    "std_x_train = x_train.values.std()\n",
    "\n",
    "# Display the results\n",
    "print(\"*******x_train\")\n",
    "print(\"Minimum values:\\n\", min_x_train)\n",
    "print(\"\\nMaximum values:\\n\", max_x_train)\n",
    "print(\"\\nMean (Average) values:\\n\", mean_x_train)\n",
    "print(\"\\nStandard Deviation values:\\n\", std_x_train)\n",
    "\n",
    "min_y_val = y_valid.values.min()\n",
    "max_y_val = y_valid.values.max()\n",
    "mean_y_val = y_valid.values.mean()\n",
    "std_y_val = y_valid.values.std()\n",
    "\n",
    "# Display the results\n",
    "print(\"*******y_val\")\n",
    "print(\"Minimum values:\\n\", min_y_val)\n",
    "print(\"\\nMaximum values:\\n\", max_y_val)\n",
    "print(\"\\nMean (Average) values:\\n\", mean_y_val)\n",
    "print(\"\\nStandard Deviation values:\\n\", std_y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:38:17.535948Z",
     "iopub.status.busy": "2025-04-05T09:38:17.535651Z",
     "iopub.status.idle": "2025-04-05T09:38:17.556736Z",
     "shell.execute_reply": "2025-04-05T09:38:17.555891Z",
     "shell.execute_reply.started": "2025-04-05T09:38:17.535924Z"
    },
    "id": "MU7NQIfqtgsy",
    "outputId": "2b1209e9-71e4-4d5f-9cba-c7c0c9b9ea39",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>390</th>\n",
       "      <th>391</th>\n",
       "      <th>392</th>\n",
       "      <th>393</th>\n",
       "      <th>394</th>\n",
       "      <th>395</th>\n",
       "      <th>396</th>\n",
       "      <th>397</th>\n",
       "      <th>398</th>\n",
       "      <th>399</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>228664</td>\n",
       "      <td>11624</td>\n",
       "      <td>20584</td>\n",
       "      <td>5648</td>\n",
       "      <td>71096.0</td>\n",
       "      <td>7932.0</td>\n",
       "      <td>82552.0</td>\n",
       "      <td>24512.0</td>\n",
       "      <td>129808.0</td>\n",
       "      <td>61712.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3388.0</td>\n",
       "      <td>8072.0</td>\n",
       "      <td>41976.0</td>\n",
       "      <td>29888.0</td>\n",
       "      <td>16376.0</td>\n",
       "      <td>9524.0</td>\n",
       "      <td>35728.0</td>\n",
       "      <td>83816.0</td>\n",
       "      <td>88696.0</td>\n",
       "      <td>1888.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>381085</td>\n",
       "      <td>2086</td>\n",
       "      <td>125152</td>\n",
       "      <td>7976</td>\n",
       "      <td>76976.0</td>\n",
       "      <td>97608.0</td>\n",
       "      <td>21248.0</td>\n",
       "      <td>1628.0</td>\n",
       "      <td>33096.0</td>\n",
       "      <td>3592.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18296.0</td>\n",
       "      <td>17272.0</td>\n",
       "      <td>19272.0</td>\n",
       "      <td>41696.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>92016.0</td>\n",
       "      <td>17248.0</td>\n",
       "      <td>23376.0</td>\n",
       "      <td>30672.0</td>\n",
       "      <td>63624.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86728</td>\n",
       "      <td>119872</td>\n",
       "      <td>45504</td>\n",
       "      <td>21936</td>\n",
       "      <td>20864.0</td>\n",
       "      <td>11176.0</td>\n",
       "      <td>21528.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>20352.0</td>\n",
       "      <td>8312.0</td>\n",
       "      <td>...</td>\n",
       "      <td>45712.0</td>\n",
       "      <td>2356.0</td>\n",
       "      <td>50912.0</td>\n",
       "      <td>26776.0</td>\n",
       "      <td>87504.0</td>\n",
       "      <td>12288.0</td>\n",
       "      <td>52752.0</td>\n",
       "      <td>10296.0</td>\n",
       "      <td>1132.0</td>\n",
       "      <td>3316.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33616</td>\n",
       "      <td>75696</td>\n",
       "      <td>2844</td>\n",
       "      <td>1796</td>\n",
       "      <td>3268.0</td>\n",
       "      <td>10784.0</td>\n",
       "      <td>31192.0</td>\n",
       "      <td>18752.0</td>\n",
       "      <td>115392.0</td>\n",
       "      <td>48296.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13532.0</td>\n",
       "      <td>25344.0</td>\n",
       "      <td>65192.0</td>\n",
       "      <td>29896.0</td>\n",
       "      <td>43512.0</td>\n",
       "      <td>21224.0</td>\n",
       "      <td>83864.0</td>\n",
       "      <td>30912.0</td>\n",
       "      <td>77656.0</td>\n",
       "      <td>49888.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27256</td>\n",
       "      <td>38408</td>\n",
       "      <td>31152</td>\n",
       "      <td>252</td>\n",
       "      <td>23448.0</td>\n",
       "      <td>1544.0</td>\n",
       "      <td>3276.0</td>\n",
       "      <td>41584.0</td>\n",
       "      <td>45968.0</td>\n",
       "      <td>2128.0</td>\n",
       "      <td>...</td>\n",
       "      <td>89328.0</td>\n",
       "      <td>2816.0</td>\n",
       "      <td>68864.0</td>\n",
       "      <td>46984.0</td>\n",
       "      <td>4308.0</td>\n",
       "      <td>22712.0</td>\n",
       "      <td>2428.0</td>\n",
       "      <td>61112.0</td>\n",
       "      <td>38792.0</td>\n",
       "      <td>272.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0       1       2      3        4        5        6        7    \\\n",
       "0  228664   11624   20584   5648  71096.0   7932.0  82552.0  24512.0   \n",
       "1  381085    2086  125152   7976  76976.0  97608.0  21248.0   1628.0   \n",
       "2   86728  119872   45504  21936  20864.0  11176.0  21528.0    284.0   \n",
       "3   33616   75696    2844   1796   3268.0  10784.0  31192.0  18752.0   \n",
       "4   27256   38408   31152    252  23448.0   1544.0   3276.0  41584.0   \n",
       "\n",
       "        8        9    ...      390      391      392      393      394  \\\n",
       "0  129808.0  61712.0  ...   3388.0   8072.0  41976.0  29888.0  16376.0   \n",
       "1   33096.0   3592.0  ...  18296.0  17272.0  19272.0  41696.0    176.0   \n",
       "2   20352.0   8312.0  ...  45712.0   2356.0  50912.0  26776.0  87504.0   \n",
       "3  115392.0  48296.0  ...  13532.0  25344.0  65192.0  29896.0  43512.0   \n",
       "4   45968.0   2128.0  ...  89328.0   2816.0  68864.0  46984.0   4308.0   \n",
       "\n",
       "       395      396      397      398      399  \n",
       "0   9524.0  35728.0  83816.0  88696.0   1888.0  \n",
       "1  92016.0  17248.0  23376.0  30672.0  63624.0  \n",
       "2  12288.0  52752.0  10296.0   1132.0   3316.0  \n",
       "3  21224.0  83864.0  30912.0  77656.0  49888.0  \n",
       "4  22712.0   2428.0  61112.0  38792.0    272.0  \n",
       "\n",
       "[5 rows x 400 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:38:17.557710Z",
     "iopub.status.busy": "2025-04-05T09:38:17.557477Z",
     "iopub.status.idle": "2025-04-05T09:38:17.572478Z",
     "shell.execute_reply": "2025-04-05T09:38:17.571540Z",
     "shell.execute_reply.started": "2025-04-05T09:38:17.557684Z"
    },
    "id": "aENzdcz9tgsz",
    "outputId": "f9f81757-94b7-4469-90d6-cec250b27e96",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (132019, 400)\n",
      "x_valid shape: (4240, 400)\n",
      "y_train shape: (132019, 60)\n",
      "y_valid shape: (4240, 60)\n"
     ]
    }
   ],
   "source": [
    "print(f\"x_train shape: {x_train_shape}\")\n",
    "print(f\"x_valid shape: {x_valid_shape}\")\n",
    "#print(f\"x_test shape: {x_test_shape}\")\n",
    "print(f\"y_train shape: {y_train_shape}\")\n",
    "print(f\"y_valid shape: {y_valid_shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aRmlDe7utgtI"
   },
   "source": [
    "## Prepare Data for training - Augmentation & Rescaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment then standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:38:17.586680Z",
     "iopub.status.busy": "2025-04-05T09:38:17.586446Z",
     "iopub.status.idle": "2025-04-05T09:38:19.709079Z",
     "shell.execute_reply": "2025-04-05T09:38:19.708167Z",
     "shell.execute_reply.started": "2025-04-05T09:38:17.586651Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (132019, 400)\n",
      "Shape of data: (132019, 60)\n"
     ]
    }
   ],
   "source": [
    "# If you need to apply augmentation, you can first standardize your data\n",
    "x_train_noisy = x_train + np.random.normal(0, 0.01, x_train.shape)  # Adding Gaussian noise\n",
    "\n",
    "y_train_noisy = y_train + np.random.normal(0, 0.01, y_train.shape) # for next-step prediction in time series or regression tasks, we should apply the same transformation to maintain consistency.\n",
    "\n",
    "# Now you have augmented data\n",
    "# We can apply more augmentations like shifting or time warping here\n",
    "\n",
    "print(\"Shape of data:\", x_train_noisy.shape)\n",
    "print(\"Shape of data:\", y_train_noisy.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:38:19.710245Z",
     "iopub.status.busy": "2025-04-05T09:38:19.709974Z",
     "iopub.status.idle": "2025-04-05T09:38:20.331697Z",
     "shell.execute_reply": "2025-04-05T09:38:20.330796Z",
     "shell.execute_reply.started": "2025-04-05T09:38:19.710213Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of combined x_train: (264038, 400)\n",
      "Shape of combined y_train: (264038, 60)\n"
     ]
    }
   ],
   "source": [
    "# Add x_train_noisy to the bottom of x_train_standardized\n",
    "x_train_aug = np.vstack((x_train, x_train_noisy))\n",
    "\n",
    "# Add y_train_noisy to the bottom of y_train_standardized\n",
    "y_train_aug = np.vstack((y_train, y_train_noisy))\n",
    "\n",
    "# Check the shapes\n",
    "print(\"Shape of combined x_train:\", x_train_aug.shape)\n",
    "print(\"Shape of combined y_train:\", y_train_aug.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:38:20.332859Z",
     "iopub.status.busy": "2025-04-05T09:38:20.332570Z",
     "iopub.status.idle": "2025-04-05T09:38:22.084100Z",
     "shell.execute_reply": "2025-04-05T09:38:22.083218Z",
     "shell.execute_reply.started": "2025-04-05T09:38:20.332837Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# StandardScaler Transformer\n",
    "\n",
    "x_scaler = StandardScaler()\n",
    "x_train_aug_std = x_scaler.fit_transform(x_train_aug)\n",
    "x_valid_standardized = x_scaler.transform(x_valid)\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_train_aug_std = y_scaler.fit_transform(y_train_aug)\n",
    "y_valid_standardized = y_scaler.transform(y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Tz-R5rTJq6_"
   },
   "source": [
    "## Define function tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:38:22.085298Z",
     "iopub.status.busy": "2025-04-05T09:38:22.085002Z",
     "iopub.status.idle": "2025-04-05T09:38:22.089259Z",
     "shell.execute_reply": "2025-04-05T09:38:22.088379Z",
     "shell.execute_reply.started": "2025-04-05T09:38:22.085266Z"
    },
    "id": "eOUhWiTUtgsp",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def flush():\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KncLMXAWtgtR"
   },
   "source": [
    "## Define Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:38:22.090308Z",
     "iopub.status.busy": "2025-04-05T09:38:22.090069Z",
     "iopub.status.idle": "2025-04-05T09:38:22.103429Z",
     "shell.execute_reply": "2025-04-05T09:38:22.102782Z",
     "shell.execute_reply.started": "2025-04-05T09:38:22.090288Z"
    },
    "id": "5SFHekCotgtS",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define EarlyStopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Monitor the validation loss\n",
    "    patience=100,         # Number of epochs to wait after the last improvement\n",
    "    restore_best_weights=True  # Restore the weights of the best model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PYTORCH - MODELES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition de l'architecture du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:38:22.106939Z",
     "iopub.status.busy": "2025-04-05T09:38:22.106711Z",
     "iopub.status.idle": "2025-04-05T09:38:22.121773Z",
     "shell.execute_reply": "2025-04-05T09:38:22.120945Z",
     "shell.execute_reply.started": "2025-04-05T09:38:22.106921Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# BiLSTM Model\n",
    "class BiLSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(BiLSTMModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 1024)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bilstm = nn.LSTM(512, hidden_size, bidirectional=True, batch_first=True, num_layers=2)\n",
    "        self.bilstm = nn.LSTM(512, hidden_size, bidirectional=True, batch_first=True, num_layers=2)\n",
    "        self.bilstm = nn.LSTM(512, hidden_size, bidirectional=True, batch_first=True, num_layers=2)\n",
    "        self.fc2 = nn.Linear(hidden_size * 2, output_size)  # *2 for bidirectional LSTM\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = x.view(-1, 2, 512)  # Adjust based on input\n",
    "        x, _ = self.bilstm(x)\n",
    "        x = x[:, -1, :]\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition de la taille du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:38:22.123306Z",
     "iopub.status.busy": "2025-04-05T09:38:22.123065Z",
     "iopub.status.idle": "2025-04-05T09:38:24.909778Z",
     "shell.execute_reply": "2025-04-05T09:38:24.908855Z",
     "shell.execute_reply.started": "2025-04-05T09:38:22.123287Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Définition de la taille du modèle\n",
    "input_size = taille_fenetre_observee\n",
    "hidden_size = 800\n",
    "output_size = taille_fenetre_a_predire  \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BiLSTMModel(input_size, hidden_size, output_size).to(device)\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "x_train_tensor = torch.tensor(x_train_aug_std, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train_aug_std, dtype=torch.float32).to(device)\n",
    "x_valid_tensor = torch.tensor(x_valid_standardized, dtype=torch.float32).to(device)\n",
    "y_valid_tensor = torch.tensor(y_valid_standardized, dtype=torch.float32).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition du monitoring de l'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:38:24.911618Z",
     "iopub.status.busy": "2025-04-05T09:38:24.910731Z",
     "iopub.status.idle": "2025-04-05T09:38:24.917327Z",
     "shell.execute_reply": "2025-04-05T09:38:24.916466Z",
     "shell.execute_reply.started": "2025-04-05T09:38:24.911594Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Custom Training Monitor\n",
    "class TrainingMonitorNotebook:\n",
    "    def __init__(self):\n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "\n",
    "    def update_plot(self, epoch, train_loss, val_loss):\n",
    "        self.train_loss.append(train_loss)\n",
    "        self.val_loss.append(val_loss)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        train_line, = plt.plot(self.train_loss, label=\"Training Loss\", color='blue')\n",
    "        val_line, = plt.plot(self.val_loss, label=\"Validation Loss\", color='orange')\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training and Validation Loss Over Epochs\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        mplcursors.cursor([train_line, val_line], hover=True)\n",
    "        plt.show()\n",
    "\n",
    "# Instantiate the monitor\n",
    "training_monitor_notebook = TrainingMonitorNotebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainement du modèle\n",
    "epochs = 450\n",
    "batch_size = 1024\n",
    "\n",
    "# Training Loop with Time Series Handling\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Shuffle les données d'entrainement après chaque epoch.\n",
    "    # Le shuffling est essfectué entre portions de série temporelle pour un meilleur apprentissage,\n",
    "    # et non entre toutes les données brutes unitaires pour ne pas supprimer les liens de la série temporelle.\n",
    "    indices = np.arange(len(x_train_tensor))\n",
    "    np.random.shuffle(indices)\n",
    "    x_train_tensor = x_train_tensor[indices]\n",
    "    y_train_tensor = y_train_tensor[indices]\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    for i in range(0, x_train_tensor.size(0), batch_size):\n",
    "        batch_x = x_train_tensor[i:i + batch_size]\n",
    "        batch_y = y_train_tensor[i:i + batch_size]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        num_batches += 1  # Count actual batches\n",
    "\n",
    "    avg_train_loss = epoch_loss / num_batches  # Fix loss calculation\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(x_valid_tensor)\n",
    "        val_loss = criterion(val_outputs, y_valid_tensor).item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] - Train Loss: {avg_train_loss:.4f} - Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Update the live plot\n",
    "    training_monitor_notebook.update_plot(epoch, avg_train_loss, val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation (optional)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    val_outputs = model(x_valid_tensor)\n",
    "    val_loss = criterion(val_outputs, y_valid_tensor)\n",
    "    print(f\"Validation Loss: {val_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T11:34:33.748229Z",
     "iopub.status.busy": "2025-04-05T11:34:33.747975Z",
     "iopub.status.idle": "2025-04-05T11:34:33.766380Z",
     "shell.execute_reply": "2025-04-05T11:34:33.765442Z",
     "shell.execute_reply.started": "2025-04-05T11:34:33.748182Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Move val_outputs to CPU, then convert to NumPy and perform inverse scaling\n",
    "y_pred = y_scaler.inverse_transform(val_outputs.cpu().numpy()).astype(int)\n",
    "#y_pred = scaler.inverse_transform(val_outputs.cpu().numpy()).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y_pred.shape: \", y_pred.shape, \"\\n\")\n",
    "\n",
    "print(y_pred[:4])\n",
    "\n",
    "print(\"\\ny_pred.min(): \",y_pred.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T11:34:33.774813Z",
     "iopub.status.busy": "2025-04-05T11:34:33.774555Z",
     "iopub.status.idle": "2025-04-05T11:34:33.790574Z",
     "shell.execute_reply": "2025-04-05T11:34:33.789760Z",
     "shell.execute_reply.started": "2025-04-05T11:34:33.774790Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Replace all negative values with zero\n",
    "y_pred = np.where(y_pred < 0, 0, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer le nRMSE\n",
    "nrmse_KPI = round(np.sqrt(mean_squared_error(y_valid, y_pred)) / (max_y_val - min_y_val), 5)\n",
    "print(f'Validation nRMSE: {nrmse_KPI}')\n",
    "\n",
    "# Calculer le RMSE\n",
    "rmse_KPI = round(np.sqrt(mean_squared_error(y_valid, y_pred)), 5)\n",
    "print(f'Validation RMSE: {rmse_KPI}')\n",
    "\n",
    "# Calculer le MAE\n",
    "mae_KPI = round(mean_absolute_error(y_valid, y_pred), 5)\n",
    "print(f'Validation MAE: {mae_KPI}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prédiction du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T11:34:33.827204Z",
     "iopub.status.busy": "2025-04-05T11:34:33.826893Z",
     "iopub.status.idle": "2025-04-05T11:34:33.914697Z",
     "shell.execute_reply": "2025-04-05T11:34:33.913738Z",
     "shell.execute_reply.started": "2025-04-05T11:34:33.827165Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert y_pred (NumPy array) to a DataFrame\n",
    "y_pred_df = pd.DataFrame(y_pred)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "y_pred_df.to_csv('y_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarde du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T11:34:33.916301Z",
     "iopub.status.busy": "2025-04-05T11:34:33.915935Z",
     "iopub.status.idle": "2025-04-05T11:34:34.222211Z",
     "shell.execute_reply": "2025-04-05T11:34:34.221280Z",
     "shell.execute_reply.started": "2025-04-05T11:34:33.916266Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import torch\n",
    "import json\n",
    "\n",
    "# Save Everything\n",
    "\n",
    "# Save model weights\n",
    "torch.save(model.state_dict(), \"modele.pth\")\n",
    "\n",
    "# Save scalers\n",
    "joblib.dump(x_scaler, \"x_scaler.pkl\")\n",
    "joblib.dump(y_scaler, \"y_scaler.pkl\")\n",
    "\n",
    "# Save model parameters (input_size, hidden_size, output_size)\n",
    "params = {\n",
    "    \"input_size\": input_size,\n",
    "    \"hidden_size\": hidden_size,\n",
    "    \"output_size\": output_size,\n",
    "    \"kpi\": {\n",
    "        \"mae\": mae_KPI,\n",
    "        \"nrmse\": nrmse_KPI,\n",
    "        \"rmse\": rmse_KPI\n",
    "    }\n",
    "}\n",
    "with open(\"modele_parametres.json\", \"w\") as f:\n",
    "    json.dump(params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T11:34:34.223708Z",
     "iopub.status.busy": "2025-04-05T11:34:34.223319Z",
     "iopub.status.idle": "2025-04-05T11:34:34.925306Z",
     "shell.execute_reply": "2025-04-05T11:34:34.924371Z",
     "shell.execute_reply.started": "2025-04-05T11:34:34.223668Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-70-a24100361199>:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_model.load_state_dict(torch.load(\"modele.pth\", map_location=device))\n"
     ]
    }
   ],
   "source": [
    "#Check the model saved\n",
    "\n",
    "# Load Everything Later\n",
    "\n",
    "# Load model parameters\n",
    "with open(\"modele_parametres.json\", \"r\") as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "loaded_input_size = params[\"input_size\"]\n",
    "loaded_hidden_size = params[\"hidden_size\"]\n",
    "loaded_output_size = params[\"output_size\"]\n",
    "\n",
    "# Reconstruct model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "loaded_model = BiLSTMModel(loaded_input_size, loaded_hidden_size, loaded_output_size).to(device)\n",
    "\n",
    "# Load model weights\n",
    "loaded_model.load_state_dict(torch.load(\"modele.pth\", map_location=device))\n",
    "loaded_model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Load scalers\n",
    "loaded_x_scaler = joblib.load(\"x_scaler.pkl\")\n",
    "loaded_y_scaler = joblib.load(\"y_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T11:34:34.926517Z",
     "iopub.status.busy": "2025-04-05T11:34:34.926153Z",
     "iopub.status.idle": "2025-04-05T11:34:35.024383Z",
     "shell.execute_reply": "2025-04-05T11:34:35.023633Z",
     "shell.execute_reply.started": "2025-04-05T11:34:34.926479Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Perform Inference on New Data\n",
    "\n",
    "x_valid_restandardized = loaded_x_scaler.transform(x_valid)\n",
    "x_valid_retensor = torch.tensor(x_valid_restandardized, dtype=torch.float32).to(device)\n",
    "\n",
    "# Ensure x_valid_tensor is on the same device\n",
    "x_valid_retensor = x_valid_retensor.to(device)\n",
    "\n",
    "# Perform inference to forecast the next x steps\n",
    "pred_model_loaded = loaded_model(x_valid_retensor)\n",
    "\n",
    "# Move to CPU before converting to NumPy\n",
    "pred_model_loaded = pred_model_loaded.cpu().detach().numpy()\n",
    "\n",
    "# Use the scaler to inverse transform\n",
    "pred_model_loaded = loaded_y_scaler.inverse_transform(pred_model_loaded).astype(int)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6086848,
     "sourceId": 9907261,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6165886,
     "sourceId": 10016306,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6753903,
     "sourceId": 11232702,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
